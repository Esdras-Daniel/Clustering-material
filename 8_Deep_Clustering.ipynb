{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilidades import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Clustering\n",
    "\n",
    "O Deep Learning envolve a construção e treinamento de redes neurais artificiais profundas para realizar tarefas complexas de aprendizado, como reconhecimento de padrões, classificação e clusterização. Nos últimos anos, o uso de técnicas de Deep Learning revolucionou a forma como a clusterização é realizada, permitindo uma abordagem mais flexível e precisa na identificação de padrões complexos nos dados. A principal vantagem do Deep Learning em relação a abordagens tradicionais de clusterização está na sua capacidade de aprender automaticamente representações de características hierárquicas dos dados, sem a necessidade de uma definição explícita de características. Isso permite que modelos de Deep Learning identifiquem padrões abstratos e latentes nos dados, que podem ser cruciais para a formação de clusters significativos.\n",
    "\n",
    "**<h1>Deep Clustering Network (DCN)</h1>**\n",
    "\n",
    "Deep Clustering Network (DCN) é uma abordagem avançada que combina técnicas de Deep Learning com a clusterização tradicional para realizar a tarefa de clusterização de dados de forma mais eficaz. O objetivo do DCN é aprender representações de dados de alta qualidade, que são então utilizadas para realizar a clusterização. Ao contrário de abordagens tradicionais, que muitas vezes requerem a definição manual de características (as features), o DCN permite que o próprio modelo aprenda representações relevantes durante o processo de treinamento.\n",
    "\n",
    "A ideia central por trás do DCN é treinar uma rede neural profunda (geralmente uma autoencoder) para codificar os dados de entrada em um espaço latente de dimensão reduzida. Esse espaço latente captura as informações mais importantes dos dados e é projetado de tal forma que os pontos de dados similares são mapeados para regiões próximas no espaço latente. Uma vez que as representações latentes são aprendidas, técnicas de clusterização tradicionais, como o K-means, são aplicadas para agrupar os pontos de dados no espaço latente em clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris, y_iris, iris_target_names = get_iris_data()\n",
    "X_wine, y_wine, wine_target_names = get_wine_data()\n",
    "X_syn_ctrl, y_syn_ctrl, syn_ctrl_target_names = get_synthetic_control_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários\n",
    "import tensorflow as tf\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Normalizando os dados\n",
    "X_syn_ctrl = zscore(X_syn_ctrl)\n",
    "X_iris = zscore(X_iris)\n",
    "X_wine = zscore(X_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_autoencoder(input_dim, encoding_dim):\n",
    "\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    encoder = tf.keras.layers.Dense(encoding_dim, activation='sigmoid')(input_layer)\n",
    "    decoder = tf.keras.layers.Dense(input_dim, activation='softmax')(encoder)\n",
    "\n",
    "    autoencoder = tf.keras.models.Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o autoencoder \n",
    "iris_input_dim = X_iris.shape[1]\n",
    "wine_input_dim = X_wine.shape[1]\n",
    "syn_ctrl_input_dim = X_syn_ctrl.shape[1]\n",
    "\n",
    "encoding_dim = 2\n",
    "\n",
    "autoencoder_syn_ctrl = return_autoencoder(syn_ctrl_input_dim, encoding_dim)\n",
    "autoencoder_wine = return_autoencoder(wine_input_dim, encoding_dim)\n",
    "autoencoder_iris = return_autoencoder(iris_input_dim, encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_syn_ctrl, y_syn_ctrl, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 10ms/step - loss: 0.6779 - val_loss: 0.6686\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6613 - val_loss: 0.6548\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6461 - val_loss: 0.6414\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6316 - val_loss: 0.6282\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.6153\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6020\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5876 - val_loss: 0.5872\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5701 - val_loss: 0.5684\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5480 - val_loss: 0.5462\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5245 - val_loss: 0.5239\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5003 - val_loss: 0.5028\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4773 - val_loss: 0.4818\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4552 - val_loss: 0.4612\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4329 - val_loss: 0.4421\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4131 - val_loss: 0.4237\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3936 - val_loss: 0.4062\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3744 - val_loss: 0.3886\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3553 - val_loss: 0.3713\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3367 - val_loss: 0.3545\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3184 - val_loss: 0.3371\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3209\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2827 - val_loss: 0.3057\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2661 - val_loss: 0.2901\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2492 - val_loss: 0.2753\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2332 - val_loss: 0.2610\n",
      "Epoch 1/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6747\n",
      "Epoch 2/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6486\n",
      "Epoch 3/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6232\n",
      "Epoch 4/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.6006\n",
      "Epoch 5/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5792\n",
      "Epoch 6/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5581\n",
      "Epoch 7/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5387\n",
      "Epoch 8/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.5217\n",
      "Epoch 9/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5043\n",
      "Epoch 10/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4881\n",
      "Epoch 11/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4727\n",
      "Epoch 12/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4579\n",
      "Epoch 13/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4449\n",
      "Epoch 14/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4310\n",
      "Epoch 15/25\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4181\n",
      "Epoch 16/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.4054\n",
      "Epoch 17/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3932\n",
      "Epoch 18/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3817\n",
      "Epoch 19/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3702\n",
      "Epoch 20/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3593\n",
      "Epoch 21/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3482\n",
      "Epoch 22/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3377\n",
      "Epoch 23/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3279\n",
      "Epoch 24/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3173\n",
      "Epoch 25/25\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.3075\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6613\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6411\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6221\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6030\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5841\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5655\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5464\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5278\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5098\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4913\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4732\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4539\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4356\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4170\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3987\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3801\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3623\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3437\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3254\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3080\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2909\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2737\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2569\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2410\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19470ba6590>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilando e treinando os autoencoders\n",
    "\n",
    "# Synthetic Control\n",
    "autoencoder_syn_ctrl.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder_syn_ctrl.fit(X_train, X_train, epochs=25, batch_size=32, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Iris\n",
    "autoencoder_iris.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder_iris.fit(X_iris, X_iris, epochs=25, batch_size=8, shuffle=True)\n",
    "\n",
    "# Wine\n",
    "autoencoder_wine.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder_wine.fit(X_wine, X_wine, epochs=25, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract latent representations\n",
    "encoder_model = tf.keras.models.Model(inputs=input_layer, outputs=encoder)\n",
    "latent_representations = encoder_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1946d5f0b50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_syn_ctrl.layers[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
